{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spotify Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-ntSB_niSMb2m-XXpRS4XRBJmiZwnHAp",
      "authorship_tag": "ABX9TyN74yyKE5LOkIsswr59bslt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanczhang7/spotifyproject/blob/master/Spotify_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw9T7jMFrkJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import statsmodels\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction import text\n",
        "import category_encoders as ce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni2XpxKNz4uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_personality_sentiment = pd.read_csv(\n",
        "    \"/content/drive/My Drive/df_personality_sentiment.csv\")\n",
        "df_songs = pd.read_csv(\"/content/drive/My Drive/df_songs.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2fJ2SK_Olx2",
        "colab_type": "text"
      },
      "source": [
        "**I am trying to predict the popularity of a song. Besides all the feature selection and engineering, model selection, and hyperparameter tuning, I have audio features and textual features of a song. Between audio features and textual features, which one will be better for predicting popularity of a song? Because I am comparing audio features and textual features, I will not use artist or album as categorical features. Also, I know that popularity is highly depedent on the release date of a song, and my data isn't time-labelled, so my models will be limited.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negxBbPLBLWc",
        "colab_type": "text"
      },
      "source": [
        "# Audio Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bpq2lJGAfnU",
        "colab_type": "code",
        "outputId": "bc7b9368-ddae-4c58-d715-a13ccbbb0979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "df_songs.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>album</th>\n",
              "      <th>name</th>\n",
              "      <th>explicit</th>\n",
              "      <th>key</th>\n",
              "      <th>mode</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "      <th>popularity</th>\n",
              "      <th>genre</th>\n",
              "      <th>duration_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Black Panther</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.618</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>-9.454</td>\n",
              "      <td>0.2970</td>\n",
              "      <td>90.035</td>\n",
              "      <td>0.480</td>\n",
              "      <td>57</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>130.613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>All The Stars</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0605</td>\n",
              "      <td>0.698</td>\n",
              "      <td>0.633</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.0926</td>\n",
              "      <td>-4.946</td>\n",
              "      <td>0.0597</td>\n",
              "      <td>96.924</td>\n",
              "      <td>0.552</td>\n",
              "      <td>78</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>232.186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>X</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.768</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2680</td>\n",
              "      <td>-8.406</td>\n",
              "      <td>0.2590</td>\n",
              "      <td>131.023</td>\n",
              "      <td>0.405</td>\n",
              "      <td>69</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>267.426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>The Ways</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0626</td>\n",
              "      <td>0.727</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.1760</td>\n",
              "      <td>-5.856</td>\n",
              "      <td>0.0488</td>\n",
              "      <td>140.080</td>\n",
              "      <td>0.589</td>\n",
              "      <td>65</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>238.893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Opps</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>0.706</td>\n",
              "      <td>0.775</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.4160</td>\n",
              "      <td>-6.819</td>\n",
              "      <td>0.3350</td>\n",
              "      <td>127.929</td>\n",
              "      <td>0.847</td>\n",
              "      <td>59</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>180.893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           artist  ... duration_s\n",
              "0  Kendrick Lamar  ...    130.613\n",
              "1  Kendrick Lamar  ...    232.186\n",
              "2  Kendrick Lamar  ...    267.426\n",
              "3  Kendrick Lamar  ...    238.893\n",
              "4  Kendrick Lamar  ...    180.893\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak7Ghd_SPTm0",
        "colab_type": "text"
      },
      "source": [
        "**I will mainly be choosing between Linear Regression, KNeighbors Regressor, and Random Forest Regressor. I start out with just Linear and KNeighbors because I haven't chosen features yet, and Random Forest won't work well on just one feature.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_VnOsKbAaT7",
        "colab_type": "code",
        "outputId": "38aeab4d-9598-41c0-fec6-c61a42f924b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LinearRegression()\n",
        ")\n",
        "\n",
        "X_train = df_songs[[\"danceability\"]]\n",
        "y_train = df_songs[\"popularity\"]\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_ = pipeline.predict(X_train)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_train_))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.15372534935818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBfmChoc3uwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "642d5ce3-4eb0-4f78-868c-780459b45549"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso()\n",
        ")\n",
        "\n",
        "X_train = df_songs[[\"danceability\"]]\n",
        "y_train = df_songs[\"popularity\"]\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_ = pipeline.predict(X_train)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_train_))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.178519406967464"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0xSaitzBAAC",
        "colab_type": "code",
        "outputId": "33311edd-0207-4f71-ed4b-aea4f5ace76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    KNeighborsRegressor()\n",
        ")\n",
        "\n",
        "X_train = df_songs[[\"danceability\"]]\n",
        "y_train = df_songs[\"popularity\"]\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_ = pipeline.predict(X_train)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_train_))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.85280998687548"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTjmpfrAPmDV",
        "colab_type": "text"
      },
      "source": [
        "**KNeighbors works better so I stick with KNeighbors when choosing features. I am not using explicit as an audio feature because it is more accurate to describe it as a textual feature.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hAEr6VRBygm",
        "colab_type": "code",
        "outputId": "3b146554-61c9-4890-e256-268445e56776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "rmse = []\n",
        "feature = []\n",
        "for features in [[\"danceability\"],\n",
        "                 [\"key\"],\n",
        "                 [\"mode\"],\n",
        "                 [\"energy\"],\n",
        "                 [\"instrumentalness\"],\n",
        "                 [\"liveness\"],\n",
        "                 [\"loudness\"],\n",
        "                 [\"acousticness\"],\n",
        "                 [\"speechiness\"],\n",
        "                 [\"tempo\"],\n",
        "                 [\"valence\"],\n",
        "                 [\"time_signature\"],\n",
        "                 [\"duration_s\"]]:\n",
        "\n",
        "  ct = make_column_transformer(\n",
        "      (StandardScaler(), features),\n",
        "      remainder = \"drop\"\n",
        "  )\n",
        "\n",
        "  pipeline = make_pipeline(\n",
        "      ct,\n",
        "      KNeighborsRegressor()\n",
        "  )\n",
        "\n",
        "  X_train = df_songs[features]\n",
        "  y_train = df_songs[\"popularity\"]\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  y_train_ = pipeline.predict(X_train)\n",
        "  feature.append(features)\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_train, y_train_)))\n",
        "\n",
        "df = {}\n",
        "df[\"feature\"] = feature\n",
        "df[\"rmse\"] = rmse\n",
        "df1 = pd.DataFrame(df)\n",
        "df1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[danceability]</td>\n",
              "      <td>17.852810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[key]</td>\n",
              "      <td>22.126037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[mode]</td>\n",
              "      <td>25.602111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[energy]</td>\n",
              "      <td>17.485040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[instrumentalness]</td>\n",
              "      <td>20.307815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[liveness]</td>\n",
              "      <td>18.295904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[loudness]</td>\n",
              "      <td>18.137016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[acousticness]</td>\n",
              "      <td>18.166840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[speechiness]</td>\n",
              "      <td>18.045152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[tempo]</td>\n",
              "      <td>18.285680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[valence]</td>\n",
              "      <td>18.565487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[time_signature]</td>\n",
              "      <td>24.224766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[duration_s]</td>\n",
              "      <td>18.317655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               feature       rmse\n",
              "0       [danceability]  17.852810\n",
              "1                [key]  22.126037\n",
              "2               [mode]  25.602111\n",
              "3             [energy]  17.485040\n",
              "4   [instrumentalness]  20.307815\n",
              "5           [liveness]  18.295904\n",
              "6           [loudness]  18.137016\n",
              "7       [acousticness]  18.166840\n",
              "8        [speechiness]  18.045152\n",
              "9              [tempo]  18.285680\n",
              "10           [valence]  18.565487\n",
              "11    [time_signature]  24.224766\n",
              "12        [duration_s]  18.317655"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xxiuYhJ3-R3",
        "colab_type": "text"
      },
      "source": [
        "**Since they had some values in the 20's I want to check the same thing for Ridge Regression to make sure they didn't just differ in predictor scores.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8O1fyhI4Qqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmse = []\n",
        "feature = []\n",
        "for features in [[\"danceability\"],\n",
        "                 [\"key\"],\n",
        "                 [\"mode\"],\n",
        "                 [\"energy\"],\n",
        "                 [\"instrumentalness\"],\n",
        "                 [\"liveness\"],\n",
        "                 [\"loudness\"],\n",
        "                 [\"acousticness\"],\n",
        "                 [\"speechiness\"],\n",
        "                 [\"tempo\"],\n",
        "                 [\"valence\"],\n",
        "                 [\"time_signature\"],\n",
        "                 [\"duration_s\"]]:\n",
        "\n",
        "  pipeline = make_pipeline(\n",
        "      StandardScaler(),\n",
        "      LinearRegression()\n",
        "  )\n",
        "\n",
        "  X_train = df_songs[features]\n",
        "  y_train = df_songs[\"popularity\"]\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  y_train_ = pipeline.predict(X_train)\n",
        "  feature.append(features)\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_train, y_train_)))\n",
        "\n",
        "df = {}\n",
        "df[\"feature\"] = feature\n",
        "df[\"rmse\"] = rmse\n",
        "df1 = pd.DataFrame(df)\n",
        "df1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gzWdUY64YoA",
        "colab_type": "text"
      },
      "source": [
        "**Ridge doesn't have anything under 20, so I'm gonna stick with KNeighbors.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC0YpW-9Pu0r",
        "colab_type": "text"
      },
      "source": [
        "**Danceability and energy are the best with error in the 17's. 7 other features are in the 18's. Since they are all qunatitative, I will just iteratively add the next best predictor until the score decreases.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw3HHjoYPsGC",
        "colab_type": "code",
        "outputId": "5e5bc862-0788-4262-c2aa-6650187781c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "rmse = []\n",
        "feature = []\n",
        "for features in [[\"danceability\", \"energy\"],\n",
        "                 [\"danceability\", \"energy\", \"speechiness\"],\n",
        "                 [\"danceability\", \"energy\", \"speechiness\", \"loudness\"],\n",
        "                 [\"danceability\", \"energy\", \"speechiness\", \"loudness\", \n",
        "                  \"acousticness\"],\n",
        "                 [\"danceability\", \"energy\", \"speechiness\", \"loudness\", \n",
        "                  \"acousticness\", \"liveness\"]]:\n",
        "\n",
        "  pipeline = make_pipeline(\n",
        "      StandardScaler(),\n",
        "      KNeighborsRegressor()\n",
        "  )\n",
        "\n",
        "  X_train = df_songs[features]\n",
        "  y_train = df_songs[\"popularity\"]\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  y_train_ = pipeline.predict(X_train)\n",
        "  feature.append(features)\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_train, y_train_)))\n",
        "\n",
        "df = {}\n",
        "df[\"feature\"] = feature\n",
        "df[\"rmse\"] = rmse\n",
        "df1 = pd.DataFrame(df)\n",
        "df1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[danceability, energy]</td>\n",
              "      <td>17.915887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[danceability, energy, speechiness]</td>\n",
              "      <td>17.274720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[danceability, energy, speechiness, loudness]</td>\n",
              "      <td>16.985452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[danceability, energy, speechiness, loudness, ...</td>\n",
              "      <td>16.879977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[danceability, energy, speechiness, loudness, ...</td>\n",
              "      <td>17.258549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature       rmse\n",
              "0                             [danceability, energy]  17.915887\n",
              "1                [danceability, energy, speechiness]  17.274720\n",
              "2      [danceability, energy, speechiness, loudness]  16.985452\n",
              "3  [danceability, energy, speechiness, loudness, ...  16.879977\n",
              "4  [danceability, energy, speechiness, loudness, ...  17.258549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sl6P8ZKZEJS",
        "colab_type": "text"
      },
      "source": [
        "**So I choose danceability, energy, speechiness, loudness, acousticness. Now that I have features, I want to try RandomForest.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLm8ZjVp6OMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "367aaf15-0bd5-417c-f592-fe8d8971c9e5"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    RandomForestRegressor(max_features=\"sqrt\")\n",
        ")\n",
        "\n",
        "X_train = df_songs[[\"danceability\", \"energy\", \"speechiness\", \"loudness\",\n",
        "                    \"acousticness\"]]\n",
        "y_train = df_songs[\"popularity\"]\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_ = pipeline.predict(X_train)\n",
        "np.sqrt(mean_squared_error(y_train, y_train_))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.394213328609897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbgAy2mk8Vn9",
        "colab_type": "text"
      },
      "source": [
        "**RandomForest does better, so I stick with it. I want to estimate test error now.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS68iDIwQz48",
        "colab_type": "code",
        "outputId": "ede46363-fe42-4207-c695-b1d4cc1e17de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    RandomForestRegressor(max_features=\"sqrt\")\n",
        ")\n",
        "\n",
        "X_train = df_songs[[\"danceability\", \"energy\", \"speechiness\", \"loudness\",\n",
        "                    \"acousticness\"]]\n",
        "y_train = df_songs[\"popularity\"]\n",
        "\n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train,\n",
        "             scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.915880785471284"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkn7qHih8lNO",
        "colab_type": "text"
      },
      "source": [
        "**It seems the model is overfitting to the data. I want to hyperparameter tune now using random search cv.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMlW-sgb9xLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "b9bd8725-d047-4c87-9567-a412220b17c1"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    RandomForestRegressor(max_features = 'sqrt')\n",
        ")\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] + [None]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
        "               'randomforestregressor__max_depth': max_depth,\n",
        "               'randomforestregressor__min_samples_split': min_samples_split,\n",
        "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
        "               'randomforestregressor__bootstrap': bootstrap}\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    pipeline, param_distributions=random_grid, n_iter=100, \n",
        "    scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "model = rs.fit(\n",
        "    df_songs[[\"danceability\", \"energy\", \"speechiness\", \"loudness\", \n",
        "              \"acousticness\"]],\n",
        "    df_songs[\"popularity\"])\n",
        "\n",
        "model.best_params_"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'randomforestregressor__bootstrap': True,\n",
              " 'randomforestregressor__max_depth': 10,\n",
              " 'randomforestregressor__min_samples_leaf': 2,\n",
              " 'randomforestregressor__min_samples_split': 10,\n",
              " 'randomforestregressor__n_estimators': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS4IIwJctMp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bce07efe-cb52-4e80-87f3-e047cce6b0b0"
      },
      "source": [
        "-model.best_score_"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-19.54008627239365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-HKE1KZBHan",
        "colab_type": "text"
      },
      "source": [
        "# Textual Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHOrmBMeBFgv",
        "colab_type": "code",
        "outputId": "76685d2b-53e4-4e1c-b65a-7c0b8075747f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "df_personality_sentiment.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>album</th>\n",
              "      <th>name</th>\n",
              "      <th>explicit</th>\n",
              "      <th>genre</th>\n",
              "      <th>chain_lyrics</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>polarity</th>\n",
              "      <th>magnitude</th>\n",
              "      <th>artistic</th>\n",
              "      <th>emotion</th>\n",
              "      <th>imagination</th>\n",
              "      <th>assertive</th>\n",
              "      <th>cheeful</th>\n",
              "      <th>outgoing</th>\n",
              "      <th>modesty</th>\n",
              "      <th>sympathy</th>\n",
              "      <th>fiery</th>\n",
              "      <th>melancholy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Black Panther</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>why i go easy \\n know why i go easy \\n wait \\n...</td>\n",
              "      <td>why i go easy know why i go easy wait king of ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.931594</td>\n",
              "      <td>0.998384</td>\n",
              "      <td>0.095272</td>\n",
              "      <td>0.387043</td>\n",
              "      <td>0.101374</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.985013</td>\n",
              "      <td>0.386352</td>\n",
              "      <td>0.921542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>All The Stars</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>love lets talk about love \\n is it anything an...</td>\n",
              "      <td>love lets talk about love is it anything and e...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.996511</td>\n",
              "      <td>0.986234</td>\n",
              "      <td>0.991554</td>\n",
              "      <td>0.747748</td>\n",
              "      <td>0.986040</td>\n",
              "      <td>0.705842</td>\n",
              "      <td>0.441873</td>\n",
              "      <td>0.842244</td>\n",
              "      <td>0.157679</td>\n",
              "      <td>0.626636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>I Am</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>everybody put three fingers in the air \\n the ...</td>\n",
              "      <td>everybody put three fingers in the air the sky...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.906971</td>\n",
              "      <td>0.318395</td>\n",
              "      <td>0.994980</td>\n",
              "      <td>0.574279</td>\n",
              "      <td>0.469771</td>\n",
              "      <td>0.320161</td>\n",
              "      <td>0.024560</td>\n",
              "      <td>0.785487</td>\n",
              "      <td>0.582447</td>\n",
              "      <td>0.669157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Big Shot</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>wakanda welcome \\n big shot hol up wait peanut...</td>\n",
              "      <td>wakanda welcome big shot hol up wait peanut bu...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.967339</td>\n",
              "      <td>0.229457</td>\n",
              "      <td>0.975867</td>\n",
              "      <td>0.382183</td>\n",
              "      <td>0.880943</td>\n",
              "      <td>0.477181</td>\n",
              "      <td>0.000747</td>\n",
              "      <td>0.270318</td>\n",
              "      <td>0.787414</td>\n",
              "      <td>0.197281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Pray For Me</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>im always ready for a war again \\n go down tha...</td>\n",
              "      <td>im always ready for a war again go down that r...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.980110</td>\n",
              "      <td>0.889895</td>\n",
              "      <td>0.977369</td>\n",
              "      <td>0.307116</td>\n",
              "      <td>0.962168</td>\n",
              "      <td>0.668731</td>\n",
              "      <td>0.864149</td>\n",
              "      <td>0.875111</td>\n",
              "      <td>0.464351</td>\n",
              "      <td>0.871338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           artist  ... melancholy\n",
              "0  Kendrick Lamar  ...   0.921542\n",
              "1  Kendrick Lamar  ...   0.626636\n",
              "2  Kendrick Lamar  ...   0.669157\n",
              "3  Kendrick Lamar  ...   0.197281\n",
              "4  Kendrick Lamar  ...   0.871338\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXZ-rAHKvBPL",
        "colab_type": "text"
      },
      "source": [
        "**I will create a new column that is polarity multiplied by magnitude. Magnitude won't be that meaningful by itself, the two together might be better than just polarity.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inzyxkj7vNth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "353e682e-d713-4214-e7c1-011ac5868d36"
      },
      "source": [
        "df_personality_sentiment[\"sentiment\"] = df_personality_sentiment[\"polarity\"] * \\\n",
        "                                        df_personality_sentiment[\"magnitude\"]\n",
        "df_personality_sentiment"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>album</th>\n",
              "      <th>name</th>\n",
              "      <th>explicit</th>\n",
              "      <th>genre</th>\n",
              "      <th>chain_lyrics</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>polarity</th>\n",
              "      <th>magnitude</th>\n",
              "      <th>artistic</th>\n",
              "      <th>emotion</th>\n",
              "      <th>imagination</th>\n",
              "      <th>assertive</th>\n",
              "      <th>cheeful</th>\n",
              "      <th>outgoing</th>\n",
              "      <th>modesty</th>\n",
              "      <th>sympathy</th>\n",
              "      <th>fiery</th>\n",
              "      <th>melancholy</th>\n",
              "      <th>popularity</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Black Panther</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>why i go easy \\n know why i go easy \\n wait \\n...</td>\n",
              "      <td>why i go easy know why i go easy wait king of ...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.931594</td>\n",
              "      <td>0.998384</td>\n",
              "      <td>0.095272</td>\n",
              "      <td>0.387043</td>\n",
              "      <td>0.101374</td>\n",
              "      <td>0.421143</td>\n",
              "      <td>0.985013</td>\n",
              "      <td>0.386352</td>\n",
              "      <td>0.921542</td>\n",
              "      <td>57</td>\n",
              "      <td>-1.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>All The Stars</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>love lets talk about love \\n is it anything an...</td>\n",
              "      <td>love lets talk about love is it anything and e...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.996511</td>\n",
              "      <td>0.986234</td>\n",
              "      <td>0.991554</td>\n",
              "      <td>0.747748</td>\n",
              "      <td>0.986040</td>\n",
              "      <td>0.705842</td>\n",
              "      <td>0.441873</td>\n",
              "      <td>0.842244</td>\n",
              "      <td>0.157679</td>\n",
              "      <td>0.626636</td>\n",
              "      <td>78</td>\n",
              "      <td>-1.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>I Am</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>everybody put three fingers in the air \\n the ...</td>\n",
              "      <td>everybody put three fingers in the air the sky...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.906971</td>\n",
              "      <td>0.318395</td>\n",
              "      <td>0.994980</td>\n",
              "      <td>0.574279</td>\n",
              "      <td>0.469771</td>\n",
              "      <td>0.320161</td>\n",
              "      <td>0.024560</td>\n",
              "      <td>0.785487</td>\n",
              "      <td>0.582447</td>\n",
              "      <td>0.669157</td>\n",
              "      <td>62</td>\n",
              "      <td>-2.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Big Shot</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>wakanda welcome \\n big shot hol up wait peanut...</td>\n",
              "      <td>wakanda welcome big shot hol up wait peanut bu...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.967339</td>\n",
              "      <td>0.229457</td>\n",
              "      <td>0.975867</td>\n",
              "      <td>0.382183</td>\n",
              "      <td>0.880943</td>\n",
              "      <td>0.477181</td>\n",
              "      <td>0.000747</td>\n",
              "      <td>0.270318</td>\n",
              "      <td>0.787414</td>\n",
              "      <td>0.197281</td>\n",
              "      <td>67</td>\n",
              "      <td>-1.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kendrick Lamar</td>\n",
              "      <td>Black Panther The Album Music From And Inspire...</td>\n",
              "      <td>Pray For Me</td>\n",
              "      <td>1</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>im always ready for a war again \\n go down tha...</td>\n",
              "      <td>im always ready for a war again go down that r...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.980110</td>\n",
              "      <td>0.889895</td>\n",
              "      <td>0.977369</td>\n",
              "      <td>0.307116</td>\n",
              "      <td>0.962168</td>\n",
              "      <td>0.668731</td>\n",
              "      <td>0.864149</td>\n",
              "      <td>0.875111</td>\n",
              "      <td>0.464351</td>\n",
              "      <td>0.871338</td>\n",
              "      <td>76</td>\n",
              "      <td>-1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>Halsey</td>\n",
              "      <td>BADLANDS (Deluxe)</td>\n",
              "      <td>Haunting</td>\n",
              "      <td>0</td>\n",
              "      <td>pop</td>\n",
              "      <td>keep on haunting \\n keep on haunting me \\n kee...</td>\n",
              "      <td>keep on haunting keep on haunting me keep on h...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.930841</td>\n",
              "      <td>0.915972</td>\n",
              "      <td>0.965041</td>\n",
              "      <td>0.019663</td>\n",
              "      <td>0.737102</td>\n",
              "      <td>0.104255</td>\n",
              "      <td>0.964988</td>\n",
              "      <td>0.768947</td>\n",
              "      <td>0.798722</td>\n",
              "      <td>0.982352</td>\n",
              "      <td>59</td>\n",
              "      <td>-1.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>Halsey</td>\n",
              "      <td>BADLANDS (Deluxe)</td>\n",
              "      <td>Gasoline</td>\n",
              "      <td>1</td>\n",
              "      <td>pop</td>\n",
              "      <td>are you insane like me been in pain like me \\n...</td>\n",
              "      <td>are you insane like me been in pain like me bo...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988442</td>\n",
              "      <td>0.748622</td>\n",
              "      <td>0.999587</td>\n",
              "      <td>0.672225</td>\n",
              "      <td>0.720852</td>\n",
              "      <td>0.430028</td>\n",
              "      <td>0.083116</td>\n",
              "      <td>0.693261</td>\n",
              "      <td>0.935605</td>\n",
              "      <td>0.962687</td>\n",
              "      <td>72</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>Halsey</td>\n",
              "      <td>BADLANDS (Deluxe)</td>\n",
              "      <td>Control</td>\n",
              "      <td>0</td>\n",
              "      <td>pop</td>\n",
              "      <td>they send me away to find them a fortune \\n a ...</td>\n",
              "      <td>they send me away to find them a fortune a che...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.995897</td>\n",
              "      <td>0.990308</td>\n",
              "      <td>0.999998</td>\n",
              "      <td>0.062743</td>\n",
              "      <td>0.096730</td>\n",
              "      <td>0.006704</td>\n",
              "      <td>0.654713</td>\n",
              "      <td>0.966235</td>\n",
              "      <td>0.990844</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>69</td>\n",
              "      <td>-1.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>Halsey</td>\n",
              "      <td>BADLANDS (Deluxe)</td>\n",
              "      <td>Young God</td>\n",
              "      <td>1</td>\n",
              "      <td>pop</td>\n",
              "      <td>he says oh baby girl you know were gonna be le...</td>\n",
              "      <td>he says oh baby girl you know were gonna be le...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.974639</td>\n",
              "      <td>0.804268</td>\n",
              "      <td>0.934779</td>\n",
              "      <td>0.226985</td>\n",
              "      <td>0.578715</td>\n",
              "      <td>0.297378</td>\n",
              "      <td>0.678562</td>\n",
              "      <td>0.892613</td>\n",
              "      <td>0.147212</td>\n",
              "      <td>0.884749</td>\n",
              "      <td>60</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>Halsey</td>\n",
              "      <td>BADLANDS (Deluxe)</td>\n",
              "      <td>I Walk The Line</td>\n",
              "      <td>0</td>\n",
              "      <td>pop</td>\n",
              "      <td>i keep a close watch on this heart of mine \\n ...</td>\n",
              "      <td>i keep a close watch on this heart of mine i k...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.982715</td>\n",
              "      <td>0.981525</td>\n",
              "      <td>0.897826</td>\n",
              "      <td>0.023096</td>\n",
              "      <td>0.724339</td>\n",
              "      <td>0.074282</td>\n",
              "      <td>0.935166</td>\n",
              "      <td>0.796644</td>\n",
              "      <td>0.190062</td>\n",
              "      <td>0.950440</td>\n",
              "      <td>55</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>827 rows  21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             artist  ... sentiment\n",
              "0    Kendrick Lamar  ...     -1.20\n",
              "1    Kendrick Lamar  ...     -1.30\n",
              "2    Kendrick Lamar  ...     -2.20\n",
              "3    Kendrick Lamar  ...     -1.30\n",
              "4    Kendrick Lamar  ...     -1.10\n",
              "..              ...  ...       ...\n",
              "822          Halsey  ...     -1.40\n",
              "823          Halsey  ...     -1.00\n",
              "824          Halsey  ...     -1.70\n",
              "825          Halsey  ...      0.22\n",
              "826          Halsey  ...      0.60\n",
              "\n",
              "[827 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5Q4YCVQ7MXG",
        "colab_type": "text"
      },
      "source": [
        "**Testing between Logistic Regression, KNeighbors, and Random Forest again. I randomly choose one feature to look at.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdKC3AEx_Jgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b02ed568-9524-43ce-a68f-26d19deca4bf"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LinearRegression()\n",
        ")\n",
        "\n",
        "X_train = df_personality_sentiment[[\"emotion\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_ = pipeline.predict(X_train)\n",
        "np.sqrt(mean_squared_error(y_train, y_train_))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.347280541425654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ixQzJEky_1x",
        "colab_type": "code",
        "outputId": "dff801b0-1d9f-4404-f326-771083ca164e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    Lasso()\n",
        ")\n",
        "\n",
        "X_train = df_personality_sentiment[[\"emotion\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_ = pipeline.predict(X_train)\n",
        "np.sqrt(mean_squared_error(y_train, y_train_))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.373106729397527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFXrudc00BhX",
        "colab_type": "code",
        "outputId": "44d25e04-2426-4b9c-a750-be3f5fd86d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    KNeighborsRegressor()\n",
        ")\n",
        "\n",
        "X_train = df_personality_sentiment[[\"emotion\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_train_ = pipeline.predict(X_train)\n",
        "np.sqrt(mean_squared_error(y_train, y_train_))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.338610798608833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Okms_wr6Ub4",
        "colab_type": "text"
      },
      "source": [
        "**KNeighbors does the best again.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TloMyLNg7var",
        "colab_type": "code",
        "outputId": "d7800d20-c8c2-4c33-8ec0-4532a73b7775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "rmse = []\n",
        "feature = []\n",
        "for features in [[\"polarity\"],\n",
        "                 [\"magnitude\"],\n",
        "                 [\"artistic\"],\n",
        "                 [\"imagination\"],\n",
        "                 [\"emotion\"],\n",
        "                 [\"assertive\"],\n",
        "                 [\"cheeful\"],\n",
        "                 [\"outgoing\"],\n",
        "                 [\"modesty\"],\n",
        "                 [\"sympathy\"],\n",
        "                 [\"fiery\"],\n",
        "                 [\"melancholy\"],\n",
        "                 [\"sentiment\"]]:\n",
        "\n",
        "  pipeline = make_pipeline(\n",
        "      StandardScaler(),\n",
        "      KNeighborsRegressor()\n",
        "  )\n",
        "  X_train = df_personality_sentiment[features]\n",
        "  y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  y_train_ = pipeline.predict(X_train)\n",
        "  feature.append(features)\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_train, y_train_)))\n",
        "\n",
        "df = {}\n",
        "df[\"feature\"] = feature\n",
        "df[\"rmse\"] = rmse\n",
        "df1 = pd.DataFrame(df)\n",
        "df1"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[polarity]</td>\n",
              "      <td>21.961073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[magnitude]</td>\n",
              "      <td>20.569535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[artistic]</td>\n",
              "      <td>17.711598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[imagination]</td>\n",
              "      <td>17.091770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[emotion]</td>\n",
              "      <td>17.338611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[assertive]</td>\n",
              "      <td>17.398655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[cheeful]</td>\n",
              "      <td>17.197266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[outgoing]</td>\n",
              "      <td>16.812650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[modesty]</td>\n",
              "      <td>17.062754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[sympathy]</td>\n",
              "      <td>17.398008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[fiery]</td>\n",
              "      <td>17.061420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[melancholy]</td>\n",
              "      <td>17.407550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[sentiment]</td>\n",
              "      <td>19.276118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          feature       rmse\n",
              "0      [polarity]  21.961073\n",
              "1     [magnitude]  20.569535\n",
              "2      [artistic]  17.711598\n",
              "3   [imagination]  17.091770\n",
              "4       [emotion]  17.338611\n",
              "5     [assertive]  17.398655\n",
              "6       [cheeful]  17.197266\n",
              "7      [outgoing]  16.812650\n",
              "8       [modesty]  17.062754\n",
              "9      [sympathy]  17.398008\n",
              "10        [fiery]  17.061420\n",
              "11   [melancholy]  17.407550\n",
              "12    [sentiment]  19.276118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__KY2MrpuyAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "60dd56a4-2bd4-4729-d0ee-b3b1f0603813"
      },
      "source": [
        "rmse = []\n",
        "feature = []\n",
        "for features in [[\"outgoing\"],\n",
        "                 [\"outgoing\", \"fiery\"],\n",
        "                 [\"outgoing\", \"fiery\", \"modesty\"],\n",
        "                 [\"outgoing\", \"fiery\", \"modesty\", \"imagination\"]]:\n",
        "\n",
        "  pipeline = make_pipeline(\n",
        "      StandardScaler(),\n",
        "      KNeighborsRegressor()\n",
        "  )\n",
        "  X_train = df_personality_sentiment[features]\n",
        "  y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  y_train_ = pipeline.predict(X_train)\n",
        "  feature.append(features)\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_train, y_train_)))\n",
        "\n",
        "df = {}\n",
        "df[\"feature\"] = feature\n",
        "df[\"rmse\"] = rmse\n",
        "df1 = pd.DataFrame(df)\n",
        "df1"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[outgoing]</td>\n",
              "      <td>16.812650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[outgoing, fiery]</td>\n",
              "      <td>17.134215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[outgoing, fiery, modesty]</td>\n",
              "      <td>17.032498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[outgoing, fiery, modesty, imagination]</td>\n",
              "      <td>17.472943</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   feature       rmse\n",
              "0                               [outgoing]  16.812650\n",
              "1                        [outgoing, fiery]  17.134215\n",
              "2               [outgoing, fiery, modesty]  17.032498\n",
              "3  [outgoing, fiery, modesty, imagination]  17.472943"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJqSt-j77Rag",
        "colab_type": "text"
      },
      "source": [
        "**Fiery just by itself is best. However, I want to do the same check with RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77QRYjR81mAk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "ce78766f-17eb-42c3-9886-fe6205074c09"
      },
      "source": [
        "rmse = []\n",
        "feature = []\n",
        "for features in [[\"outgoing\"],\n",
        "                 [\"outgoing\", \"fiery\"],\n",
        "                 [\"outgoing\", \"fiery\", \"modesty\"],\n",
        "                 [\"outgoing\", \"fiery\", \"modesty\", \"imagination\"],\n",
        "                 [\"outgoing\", \"fiery\", \"modesty\", \"imagination\", \"cheeful\"],\n",
        "                 [\"outgoing\", \"fiery\", \"modesty\", \"imagination\", \"cheeful\",\n",
        "                  \"emotion\"]]:\n",
        "\n",
        "  pipeline = make_pipeline(\n",
        "      StandardScaler(),\n",
        "      RandomForestRegressor(max_features=\"sqrt\")\n",
        "  )\n",
        "  X_train = df_personality_sentiment[features]\n",
        "  y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  y_train_ = pipeline.predict(X_train)\n",
        "  feature.append(features)\n",
        "  rmse.append(np.sqrt(mean_squared_error(y_train, y_train_)))\n",
        "\n",
        "df = {}\n",
        "df[\"feature\"] = feature\n",
        "df[\"rmse\"] = rmse\n",
        "df1 = pd.DataFrame(df)\n",
        "df1"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[outgoing]</td>\n",
              "      <td>8.617519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[outgoing, fiery]</td>\n",
              "      <td>7.906745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[outgoing, fiery, modesty]</td>\n",
              "      <td>7.619998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[outgoing, fiery, modesty, imagination]</td>\n",
              "      <td>7.628521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[outgoing, fiery, modesty, imagination, cheeful]</td>\n",
              "      <td>7.484226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[outgoing, fiery, modesty, imagination, cheefu...</td>\n",
              "      <td>7.614578</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature      rmse\n",
              "0                                         [outgoing]  8.617519\n",
              "1                                  [outgoing, fiery]  7.906745\n",
              "2                         [outgoing, fiery, modesty]  7.619998\n",
              "3            [outgoing, fiery, modesty, imagination]  7.628521\n",
              "4   [outgoing, fiery, modesty, imagination, cheeful]  7.484226\n",
              "5  [outgoing, fiery, modesty, imagination, cheefu...  7.614578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQaecFLR3ylI",
        "colab_type": "text"
      },
      "source": [
        "**I just want to check if RandomForest is overfitting compared to the Kneighbors, so I check the cross-val for both.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E72KCJd94TsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a5abab0-ad29-4a4a-89cc-7fa5405aa6df"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "      StandardScaler(),\n",
        "      KNeighborsRegressor()\n",
        "  )\n",
        "\n",
        "X_train = df_personality_sentiment[[\"outgoing\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "  \n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.257367268515193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aqBm3PC15-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73b19df3-9da7-42c2-8c18-49f13f125d4e"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "      StandardScaler(),\n",
        "      RandomForestRegressor(max_features=\"sqrt\")\n",
        "  )\n",
        "\n",
        "X_train = df_personality_sentiment[[\"outgoing\", \"fiery\", \"modesty\", \n",
        "                                    \"imagination\", \"cheeful\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "  \n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.001239315263923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Th6l7g-4bkO",
        "colab_type": "text"
      },
      "source": [
        "**RandomForest does still perform a little better. Now, since I decided to consider explicit as a textual features, I add it.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlMxsh5N4smk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87a89f7a-09c5-45c3-9d8a-7a7b8907ef65"
      },
      "source": [
        "ct = make_column_transformer(\n",
        "    (OneHotEncoder(), [\"explicit\"])\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "      ct,\n",
        "      StandardScaler(),\n",
        "      RandomForestRegressor(max_features=\"sqrt\")\n",
        "  )\n",
        "\n",
        "X_train = df_personality_sentiment[[\"outgoing\", \"fiery\", \"modesty\", \n",
        "                                    \"imagination\", \"cheeful\", \"explicit\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "  \n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.27278910671483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS2TrcEj6ken",
        "colab_type": "text"
      },
      "source": [
        "**I want to try some categorical encodings from the category_encoders package to see if they work better than OneHotEncoder.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQcaCKa06b5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d81c8875-90a5-4420-e9f9-fcb64955d970"
      },
      "source": [
        "ct = make_column_transformer(\n",
        "    (ce.TargetEncoder(), [\"explicit\"])\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "      ct,\n",
        "      StandardScaler(),\n",
        "      RandomForestRegressor(max_features=\"sqrt\")\n",
        "  )\n",
        "\n",
        "X_train = df_personality_sentiment[[\"outgoing\", \"fiery\", \"modesty\", \n",
        "                                    \"imagination\", \"cheeful\", \"explicit\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "  \n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.248401384120392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0hrQ7-j6rds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e9a7723a-1889-4bbb-ec0e-43d82652c13c"
      },
      "source": [
        "ct = make_column_transformer(\n",
        "    (ce.CatBoostEncoder(), [\"explicit\"])\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "      ct,\n",
        "      StandardScaler(),\n",
        "      RandomForestRegressor(max_features=\"sqrt\")\n",
        "  )\n",
        "\n",
        "X_train = df_personality_sentiment[[\"outgoing\", \"fiery\", \"modesty\", \n",
        "                                    \"imagination\", \"cheeful\", \"explicit\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "  \n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.132705721492357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvXVRCrq7rPg",
        "colab_type": "text"
      },
      "source": [
        "**So TargetEncoder works the best.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQtVieXm7uZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "87ab4029-0aed-4768-a200-8c5ec44e3020"
      },
      "source": [
        "ct = make_column_transformer(\n",
        "    (ce.TargetEncoder(), [\"explicit\"])\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ct,\n",
        "    StandardScaler(),\n",
        "    RandomForestRegressor(max_features = 'sqrt')\n",
        ")\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] + [None]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
        "               'randomforestregressor__max_depth': max_depth,\n",
        "               'randomforestregressor__min_samples_split': min_samples_split,\n",
        "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
        "               'randomforestregressor__bootstrap': bootstrap}\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    pipeline, param_distributions=random_grid, n_iter=100, \n",
        "    scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "model = rs.fit(\n",
        "    df_personality_sentiment[[\"outgoing\", \"fiery\", \"modesty\", \n",
        "                              \"imagination\", \"cheeful\", \"explicit\"]],\n",
        "    df_personality_sentiment[\"popularity\"]\n",
        "    )\n",
        "\n",
        "model.best_params_"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 61\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'randomforestregressor__bootstrap': True,\n",
              " 'randomforestregressor__max_depth': 60,\n",
              " 'randomforestregressor__min_samples_leaf': 1,\n",
              " 'randomforestregressor__min_samples_split': 5,\n",
              " 'randomforestregressor__n_estimators': 300}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxOCQF5cLjm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc7fef7b-ce1b-4221-ebd6-aa0fb70d37ab"
      },
      "source": [
        "-model.best_score_"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.249630112235714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUTapFNajiiU",
        "colab_type": "text"
      },
      "source": [
        "**The best textual features model beat the best audio features model 19.37 < 19.54. However, they are very close. Likely they are both just bad because there aren't time labels.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paE80poVdYOb",
        "colab_type": "text"
      },
      "source": [
        "# Lyrical Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VlZdj4O-bhj",
        "colab_type": "text"
      },
      "source": [
        "**Now I try a model using idf on the lyrics. I use stopwords that I used for my ngram bar chart.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vKfA1Wr99yV",
        "colab_type": "code",
        "outputId": "c006a044-bd3a-42e2-914e-5f22366f453e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "my_stop_words = text.ENGLISH_STOP_WORDS.union(\n",
        "      [\"oh\", \"yeah\", \"im\", \"hey\"])\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(stop_words=my_stop_words),\n",
        "    RandomForestRegressor(max_features = 'sqrt')\n",
        ")\n",
        "\n",
        "cv_errs = -cross_val_score(pipeline,\n",
        "             df_personality_sentiment[\"lyrics\"],\n",
        "             df_personality_sentiment[\"popularity\"], \n",
        "             scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.45523398157722"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raFJ4eLcBbcY",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameter tuning the lyric model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVuRiuwhzOIL",
        "colab_type": "code",
        "outputId": "1021b882-67a5-4d9d-fd34-dfb587235e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "my_stop_words = text.ENGLISH_STOP_WORDS.union(\n",
        "      [\"oh\", \"yeah\", \"im\", \"hey\"])\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(stop_words=my_stop_words),\n",
        "    RandomForestRegressor(max_features = 'sqrt')\n",
        ")\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] + [None]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
        "               'randomforestregressor__max_depth': max_depth,\n",
        "               'randomforestregressor__min_samples_split': min_samples_split,\n",
        "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
        "               'randomforestregressor__bootstrap': bootstrap}\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    pipeline, param_distributions = random_grid, n_iter = 100, \n",
        "    scoring=\"neg_root_mean_squared_error\", cv = 10)\n",
        "\n",
        "model = rs.fit(\n",
        "    df_personality_sentiment[\"lyrics\"],\n",
        "    df_personality_sentiment[\"popularity\"])\n",
        "\n",
        "model.best_params_"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'randomforestregressor__bootstrap': False,\n",
              " 'randomforestregressor__max_depth': 20,\n",
              " 'randomforestregressor__min_samples_leaf': 4,\n",
              " 'randomforestregressor__min_samples_split': 5,\n",
              " 'randomforestregressor__n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbM68NQs3LOk",
        "colab_type": "code",
        "outputId": "51165f02-97bf-4f81-df12-fab632e17b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.best_score_"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-19.095938883814654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwlwuYfYAi-5",
        "colab_type": "text"
      },
      "source": [
        "**It seems just predicting using the lyrics itselfs beats audio or textual features. There is so much dimensionality from a idf transformation that adding textual features wouldn't really change the model at all.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpAYi7mMdQPb",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP2ty64od8PG",
        "colab_type": "text"
      },
      "source": [
        "**Now I want to try something new to me with XGBoost, on the lyric model and textual features model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_TpozjragGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EcXDUwdaohR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "bac0219d-f9b8-4320-db1b-093a2e53767e"
      },
      "source": [
        "X_train = df_personality_sentiment[[\"outgoing\", \"fiery\", \"modesty\", \n",
        "                                    \"imagination\", \"cheeful\", \"explicit\"]]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "ct = make_column_transformer(\n",
        "    (ce.TargetEncoder(), [\"explicit\"])\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "      ct,\n",
        "      StandardScaler(),\n",
        "      XGBRegressor(objective='reg:squarederror', n_estimators=1000, \n",
        "                   learning_rate=0.05, early_stopping_rounds=5, \n",
        "                   eval_set=[(X_train, y_train)])\n",
        "  )\n",
        "\n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.26089777901664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhn_1gkCdkEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "51aa00b0-64a8-4cf4-f1ae-0762d934e36c"
      },
      "source": [
        "X_train = df_personality_sentiment[\"lyrics\"]\n",
        "y_train = df_personality_sentiment[\"popularity\"]\n",
        "\n",
        "my_stop_words = text.ENGLISH_STOP_WORDS.union(\n",
        "      [\"oh\", \"yeah\", \"im\", \"hey\"])\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(stop_words=my_stop_words),\n",
        "    XGBRegressor(objective='reg:squarederror', n_estimators=500, \n",
        "                   learning_rate=0.05, early_stopping_rounds=5, \n",
        "                   eval_set=[(X_train, y_train)])\n",
        ")\n",
        "\n",
        "cv_errs = -cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"neg_root_mean_squared_error\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.756357166704266"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsG0LYV0fCfC",
        "colab_type": "text"
      },
      "source": [
        "**Neither was improved by using XGBoost.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjmeXYsqIqjo",
        "colab_type": "text"
      },
      "source": [
        "# Bigram Markov Chain Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf3jeR9ZItf6",
        "colab_type": "text"
      },
      "source": [
        "**Just for fun I use a bigram markov chain model to generate lyrics from each genre, and use that as a different approach to approximate test error for guessing something simple like genre off the lyrics of a song. I won't have any audio features or textual features on these lyrics. I could get textual features like before but audio.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txf6jdFkgBuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex8R68Vtfuzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9db2f9e-f734-4b43-e1af-92a6fb520b0d"
      },
      "source": [
        "X_train = df_personality_sentiment[\"lyrics\"]\n",
        "y_train = df_personality_sentiment[\"genre\"]\n",
        "\n",
        "my_stop_words = text.ENGLISH_STOP_WORDS.union(\n",
        "      [\"oh\", \"yeah\", \"im\", \"hey\"])\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(stop_words=my_stop_words),\n",
        "    RandomForestClassifier(max_features = 'sqrt')\n",
        ")\n",
        "\n",
        "cv_errs = cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"f1_macro\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8446075580593913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ehPWO1g2vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "8f920b97-397e-43c1-e30c-aec5cdc575b2"
      },
      "source": [
        "my_stop_words = text.ENGLISH_STOP_WORDS.union(\n",
        "      [\"oh\", \"yeah\", \"im\", \"hey\"])\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(stop_words=my_stop_words),\n",
        "    RandomForestClassifier(max_features = 'sqrt')\n",
        ")\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] + [None]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
        "               'randomforestclassifier__max_depth': max_depth,\n",
        "               'randomforestclassifier__min_samples_split': min_samples_split,\n",
        "               'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
        "               'randomforestclassifier__bootstrap': bootstrap}\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    pipeline, param_distributions = random_grid, n_iter = 100, \n",
        "    scoring=\"f1_macro\", cv = 10)\n",
        "\n",
        "model = rs.fit(\n",
        "    df_personality_sentiment[\"lyrics\"],\n",
        "    df_personality_sentiment[\"genre\"])\n",
        "\n",
        "model.best_params_"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'randomforestclassifier__bootstrap': False,\n",
              " 'randomforestclassifier__max_depth': 40,\n",
              " 'randomforestclassifier__min_samples_leaf': 1,\n",
              " 'randomforestclassifier__min_samples_split': 5,\n",
              " 'randomforestclassifier__n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw8yawtDhS1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3be2dcd5-30ad-47d9-ca8a-d42afb9cb329"
      },
      "source": [
        "model.best_score_"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8547687257625896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XdLc17IsUrY",
        "colab_type": "text"
      },
      "source": [
        "**This is the best model for predicting genre.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzkwwkWAniov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7cb718fd-8aa3-460a-f343-a7c006fdd9f4"
      },
      "source": [
        "my_stop_words = text.ENGLISH_STOP_WORDS.union(\n",
        "      [\"oh\", \"yeah\", \"im\", \"hey\"])\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(stop_words=my_stop_words),\n",
        "    RandomForestClassifier(max_features = 'sqrt', n_estimators=100,\n",
        "                           max_depth=40, min_samples_split=5,\n",
        "                           min_samples_leaf=1, bootstrap=False)\n",
        ")\n",
        "\n",
        "X_train = df_personality_sentiment[\"lyrics\"]\n",
        "y_train = df_personality_sentiment[\"genre\"]\n",
        "\n",
        "cv_errs = cross_val_score(pipeline, X_train, y_train, \n",
        "                          scoring=\"f1_macro\", cv=10)\n",
        "\n",
        "cv_errs.mean()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8454914532964939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxKN9rnNBTre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bigrams(words):\n",
        "    return zip(words, words[1:])\n",
        "\n",
        "def train_markov_chain(lyrics):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - lyrics: a list of strings, where each string represents\n",
        "                the lyrics of one song by an artist.\n",
        "    \n",
        "    Returns:\n",
        "      A dict that maps a single word (\"unigram\") to a list of\n",
        "      words that follow that word, representing the Markov\n",
        "      chain trained on the lyrics.\n",
        "    \"\"\"\n",
        "    chain = {\"<START>\": []}\n",
        "    for lyric in lyrics:\n",
        "      lyric[:0] = [\"<START>\"] \n",
        "      lyric.append(\"<END>\")\n",
        "      lyric_bigrams = get_bigrams(lyric)\n",
        "      for bigram in list(lyric_bigrams):\n",
        "        if bigram[0] not in chain:\n",
        "          chain[bigram[0]] = []\n",
        "        chain[bigram[0]].append(bigram[1])\n",
        "        # YOUR CODE HERE\n",
        "        pass\n",
        "        \n",
        "    return chain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIdChj-sCV_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_hiphop = df_personality_sentiment[\n",
        "       df_personality_sentiment[\"genre\"]==\"hiphop\"][\"chain_lyrics\"].str.split()\n",
        "tokens_pop = df_personality_sentiment[\n",
        "       df_personality_sentiment[\"genre\"]==\"pop\"][\"chain_lyrics\"].str.split()\n",
        "       \n",
        "markov_hiphop = train_markov_chain(tokens_hiphop)\n",
        "markov_pop = train_markov_chain(tokens_pop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FlcbE-FKaOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def generate_new_lyrics(chain):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - chain: a dict representing the Markov chain\n",
        "    \n",
        "    Returns:\n",
        "      A string representing the randomly generated song.\n",
        "    \"\"\"\n",
        "    \n",
        "    # a list for storing the generated words\n",
        "    words = []\n",
        "    # generate the first word\n",
        "    words.append(random.choice(chain[\"<START>\"]))\n",
        "    i = 0\n",
        "    while words[i] != \"<END>\":\n",
        "      words.append(random.choice(chain[words[i]]))\n",
        "      i += 1\n",
        "    \n",
        "    # join the words together into a string with line breaks\n",
        "    lyrics = \" \".join(words[:-1])\n",
        "    return \"\\n\".join(lyrics.split(\"<N>\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAedlWlhoArt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "32403e54-1ca9-4bac-fd26-27b35bcde805"
      },
      "source": [
        "new_pop = []\n",
        "new_hiphop = []\n",
        "for i in range(500):\n",
        "  new_pop.append(generate_new_lyrics(markov_pop))\n",
        "for i in range(500):\n",
        "  new_hiphop.append(generate_new_lyrics(markov_hiphop))\n",
        "\n",
        "df = {}\n",
        "df[\"pop_lyrics\"] = new_pop\n",
        "df[\"hiphop_lyrics\"] = new_hiphop\n",
        "df1 = pd.DataFrame(df)\n",
        "df1"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pop_lyrics</th>\n",
              "      <th>hiphop_lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>youve ever getting back i close handful of us ...</td>\n",
              "      <td>mass hallucination baby baby platinum on the d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>climb the way home and i lost in a different p...</td>\n",
              "      <td>right back i give it moving got some different...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i i was a sign i shouldve said i i can pick it...</td>\n",
              "      <td>you the trap trapmoneybenny this nothing for r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>center of something real bad idea forget the o...</td>\n",
              "      <td>ive got friends way heading up bitch dont shin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>its the sky does this way beneath this is an o...</td>\n",
              "      <td>cant photoshop me later we slang no my grip lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>we see youre a deep cut deep as if i remember ...</td>\n",
              "      <td>unread texts i do and you only upsets me and g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>put your ways i been on me love the attitude y...</td>\n",
              "      <td>these niggas only if i know i got court drop d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>bada bing youll believe that you are where you...</td>\n",
              "      <td>new nigga pull in the left side yall niggas fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>youve been with my baby come on a negative way...</td>\n",
              "      <td>hendrix ah do im in public blame the flow dumb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>tell santa claus is be me down my true love hi...</td>\n",
              "      <td>when you catch me and gnarly i will deny facts...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            pop_lyrics                                      hiphop_lyrics\n",
              "0    youve ever getting back i close handful of us ...  mass hallucination baby baby platinum on the d...\n",
              "1    climb the way home and i lost in a different p...  right back i give it moving got some different...\n",
              "2    i i was a sign i shouldve said i i can pick it...  you the trap trapmoneybenny this nothing for r...\n",
              "3    center of something real bad idea forget the o...  ive got friends way heading up bitch dont shin...\n",
              "4    its the sky does this way beneath this is an o...  cant photoshop me later we slang no my grip lo...\n",
              "..                                                 ...                                                ...\n",
              "495  we see youre a deep cut deep as if i remember ...  unread texts i do and you only upsets me and g...\n",
              "496  put your ways i been on me love the attitude y...  these niggas only if i know i got court drop d...\n",
              "497  bada bing youll believe that you are where you...  new nigga pull in the left side yall niggas fo...\n",
              "498  youve been with my baby come on a negative way...  hendrix ah do im in public blame the flow dumb...\n",
              "499  tell santa claus is be me down my true love hi...  when you catch me and gnarly i will deny facts...\n",
              "\n",
              "[500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8rUtH5Tq1rF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7d03b9e-91fa-4582-824c-7fac456de441"
      },
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "list(pipeline.predict(df1[\"pop_lyrics\"])).count(\"pop\")/500"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACury4L9rzFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a565407d-1b84-41ae-a959-de3a375eb968"
      },
      "source": [
        "list(pipeline.predict(df1[\"hiphop_lyrics\"])).count(\"hiphop\")/500"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvB36mPHr787",
        "colab_type": "text"
      },
      "source": [
        "**If we can consider lyrics generating from a markov chain model of hiphop lyrics to be truely hiphop, then these models could be a good way to estimate test error. The new lyrics are not independent of the the old ones, but the inverse document frequecies should be different. This model is better at predicting pop lyrics than hiphop lyrics.**"
      ]
    }
  ]
}